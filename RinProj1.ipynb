{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df0afe2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.4.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.3.4)\n",
      "Requirement already satisfied: torch>=1.11 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.12.0+cu116)\n",
      "Requirement already satisfied: numpy in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.19.5)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.0.0)\n",
      "Requirement already satisfied: gym==0.21 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.21.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.6.0.66)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.9.0)\n",
      "Requirement already satisfied: protobuf~=3.19.0 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.19.4)\n",
      "Requirement already satisfied: ale-py==0.7.4 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.7.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (5.8.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (8.4.0)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from ale-py==0.7.4->stable-baselines3[extra]) (4.12.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from ale-py==0.7.4->stable-baselines3[extra]) (5.9.0)\n",
      "Requirement already satisfied: click in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (8.0.3)\n",
      "Requirement already satisfied: requests in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.26.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (4.62.3)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.10.0->ale-py==0.7.4->stable-baselines3[extra]) (3.6.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (2.0.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (2.6.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.3.7)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.37.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (58.0.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.15.0)\n",
      "Requirement already satisfied: six in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from absl-py>=0.4->tensorboard>=2.2.0->stable-baselines3[extra]) (1.15.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2022.5.18.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (3.7.4.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from click->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (0.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2021.3)\n"
     ]
    }
   ],
   "source": [
    "pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cf1358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6215736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1970ac1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017fbbef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab115674",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyglet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c4ebd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import pyglet\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d08a0ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = 'CartPole-v0'\n",
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c90532d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:18.0\n",
      "Episode:2 Score:13.0\n",
      "Episode:3 Score:36.0\n",
      "Episode:4 Score:11.0\n",
      "Episode:5 Score:13.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97baab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "762d0845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    print(episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "543ae844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.4117963e+00,  2.3544223e+38,  4.1726556e-02, -1.5540995e+38],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bad3ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48ef0ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training\\\\Logs'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ea442c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "068ab2e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_7\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1583 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1107         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033536423 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.562       |\n",
      "|    explained_variance   | 0.324        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    value_loss           | 7.1          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1003         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031156281 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.777        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.33         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.000886    |\n",
      "|    value_loss           | 4.64         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 904          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048245336 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.562       |\n",
      "|    explained_variance   | 0.811        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.328        |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    value_loss           | 5.15         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 842         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008408431 |\n",
      "|    clip_fraction        | 0.0643      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.544      |\n",
      "|    explained_variance   | 0.779       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.22        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    value_loss           | 1.71        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 813         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004225954 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.529      |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00115    |\n",
      "|    value_loss           | 1.15        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 799          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028492592 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.536       |\n",
      "|    explained_variance   | 0.159        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.107        |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    value_loss           | 0.788        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 804         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006400032 |\n",
      "|    clip_fraction        | 0.0378      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.536      |\n",
      "|    explained_variance   | -0.0639     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0399      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    value_loss           | 0.487       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 804          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043748515 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.525       |\n",
      "|    explained_variance   | -0.0157      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0544       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    value_loss           | 0.313        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 806          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054709543 |\n",
      "|    clip_fraction        | 0.0492       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.525       |\n",
      "|    explained_variance   | 0.0784       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0345       |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    value_loss           | 0.208        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 809          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045698504 |\n",
      "|    clip_fraction        | 0.0252       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.516       |\n",
      "|    explained_variance   | 0.165        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0158       |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    value_loss           | 0.135        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 810          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025772112 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.52        |\n",
      "|    explained_variance   | -0.0354      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0363       |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.000414    |\n",
      "|    value_loss           | 0.0875       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 811          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033484823 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.519       |\n",
      "|    explained_variance   | 0.163        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00388     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    value_loss           | 0.0582       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 814         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004493663 |\n",
      "|    clip_fraction        | 0.0251      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.514      |\n",
      "|    explained_variance   | 0.0871      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.015       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    value_loss           | 0.0369      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 815          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047483044 |\n",
      "|    clip_fraction        | 0.0455       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.519       |\n",
      "|    explained_variance   | 0.127        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0138       |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    value_loss           | 0.0247       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 816          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057670744 |\n",
      "|    clip_fraction        | 0.0549       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | 0.0236       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00584      |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    value_loss           | 0.0172       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 819         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005562805 |\n",
      "|    clip_fraction        | 0.0554      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.513      |\n",
      "|    explained_variance   | -0.0375     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00831     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    value_loss           | 0.0113      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 821         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002488725 |\n",
      "|    clip_fraction        | 0.0118      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.534      |\n",
      "|    explained_variance   | -0.0196     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00172    |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.000754   |\n",
      "|    value_loss           | 0.00807     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 820          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043148026 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | -0.00797     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00321     |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.000924    |\n",
      "|    value_loss           | 0.00541      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 782          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063773463 |\n",
      "|    clip_fraction        | 0.0451       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0392       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0149       |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    value_loss           | 0.00378      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 770          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053661177 |\n",
      "|    clip_fraction        | 0.0554       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | -0.00436     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00689     |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    value_loss           | 0.00261      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 762         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004419471 |\n",
      "|    clip_fraction        | 0.019       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.518      |\n",
      "|    explained_variance   | -0.0652     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00953    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.000864   |\n",
      "|    value_loss           | 0.00184     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 753          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026620096 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | -0.0132      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0132      |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    value_loss           | 0.00135      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 696        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 70         |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00437224 |\n",
      "|    clip_fraction        | 0.0473     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.503     |\n",
      "|    explained_variance   | 0.0445     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00363   |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.00387   |\n",
      "|    value_loss           | 0.000941   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 676          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033795433 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | -0.0853      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000732     |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.000648    |\n",
      "|    value_loss           | 0.000679     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1c94e4cd2a0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ce598bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Path = os.path.join('Training', 'Saved Models', 'PPO_Model_Cartpole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dbfffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bba6d329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhishek\\RLPR\\rlcourse\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200.0, 0.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6a7e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "565749af",
   "metadata": {},
   "outputs": [],
   "source": [
    "action, _ = model.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e4ca42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ef7401a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:[200.]\n",
      "Episode:2 Score:[200.]\n",
      "Episode:3 Score:[200.]\n",
      "Episode:4 Score:[200.]\n",
      "Episode:5 Score:[200.]\n",
      "Episode:6 Score:[200.]\n",
      "Episode:7 Score:[200.]\n",
      "Episode:8 Score:[200.]\n",
      "Episode:9 Score:[200.]\n",
      "Episode:10 Score:[200.]\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69754b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69990697",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log_path = os.path.join(log_path,'PPO_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29747628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training\\\\Logs\\\\PPO_3'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8f2c306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "tensorboard --logdir={training_log_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd6eeb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed9c562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'Saved Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6191bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=200, verbose=1)\n",
    "eval_callback = EvalCallback(env, callback_on_new_best=stop_callback, eval_freq=10000, best_model_save_path=save_path, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b9834af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2351af99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_8\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1170 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 641         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008490616 |\n",
      "|    clip_fraction        | 0.0947      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.687      |\n",
      "|    explained_variance   | -0.00316    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.96        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 48.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 610         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013792057 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.666      |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.86        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 615         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008364975 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.632      |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=179.20 +/- 17.37\n",
      "Episode length: 179.20 +/- 17.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 179          |\n",
      "|    mean_reward          | 179          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068632243 |\n",
      "|    clip_fraction        | 0.0675       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.602       |\n",
      "|    explained_variance   | 0.321        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 29.7         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    value_loss           | 62.7         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 574   |\n",
      "|    iterations      | 5     |\n",
      "|    time_elapsed    | 17    |\n",
      "|    total_timesteps | 10240 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 603         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008966526 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.587      |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    value_loss           | 51.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 626         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007880986 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.583      |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.48        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    value_loss           | 53.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 644         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007415504 |\n",
      "|    clip_fraction        | 0.0464      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.578      |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    value_loss           | 40.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 660          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028860378 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.576       |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.22         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    value_loss           | 34.6         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=200.00 +/- 0.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 200          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 20000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037467421 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.56        |\n",
      "|    explained_variance   | 0.0545       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.883        |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    value_loss           | 27.2         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "Stopping training because the mean reward 200.00  is above the threshold 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1c95c12b6d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "485d2a18",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:[176.]\n",
      "Episode:2 Score:[200.]\n",
      "Episode:3 Score:[200.]\n",
      "Episode:4 Score:[179.]\n",
      "Episode:5 Score:[200.]\n",
      "Episode:6 Score:[200.]\n",
      "Episode:7 Score:[200.]\n",
      "Episode:8 Score:[200.]\n",
      "Episode:9 Score:[200.]\n",
      "Episode:10 Score:[200.]\n",
      "Episode:11 Score:[200.]\n",
      "Episode:12 Score:[89.]\n",
      "Episode:13 Score:[200.]\n",
      "Episode:14 Score:[200.]\n",
      "Episode:15 Score:[200.]\n",
      "Episode:16 Score:[200.]\n",
      "Episode:17 Score:[200.]\n",
      "Episode:18 Score:[200.]\n",
      "Episode:19 Score:[200.]\n",
      "Episode:20 Score:[200.]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa2fa41d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69770179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlcourse",
   "language": "python",
   "name": "rlcourse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
